{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_fraud():\n",
    "    #returns percentage of observations that are fraud\n",
    "    df = pd.read_csv('fraud_data.csv')\n",
    "    df.head()\n",
    "    percent_fraud = len(df[df['Class'] == 1])/len(df[df['Class'] == 0])\n",
    "    \n",
    "    return percent_fraud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_performance(): #training a dummy classifier and evaluating its performance based on accuracy and recall\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    from sklearn.metrics import recall_score\n",
    "    dc = DummyClassifier(strategy = 'most_frequent')\n",
    "    dclf = dc.fit(X_train, y_train)\n",
    "    pred = dclf.predict(X_test)\n",
    "    acc_score = dc.score(X_test, y_test)\n",
    "    rec_score = recall_score(y_test, pred, average = 'binary')\n",
    "    \n",
    "    \n",
    "    return (acc_score, rec_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_performance(): #checking accuracy, recall and precision core of SVC classifier\n",
    "    from sklearn.metrics import recall_score, precision_score\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC().fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    acc_score = clf.score(X_test, y_test)\n",
    "    rec_score = recall_score(y_test, pred, average = 'binary')\n",
    "    prec_score = precision_score(y_test, pred, average = 'binary')\n",
    "    return (acc_score, rec_score, prec_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_perfromance_confusion_matrix(): #returns a confusion matrix with SVC performance with parameters 'C' = 1e9 and gamma =  1e-07\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(C = 1e9, gamma = 1e-07)\n",
    "    clf = svm.fit(X_train, y_train)\n",
    "    pred = clf.decision_function(X_test) > -220\n",
    "    matrix = confusion_matrix(y_test, pred)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a logistic regression Creating precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "\n",
    "y_prob_score = LogisticRegression().fit(X_train, y_train).predict_proba(X_test)\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "precision, recall, threshold = precision_recall_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(precision, recall, label = 'precision-recall curve')\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.66666667,  0.76086957],\n",
       "       [ 0.80072464,  0.80434783],\n",
       "       [ 0.8115942 ,  0.8115942 ],\n",
       "       [ 0.80797101,  0.8115942 ],\n",
       "       [ 0.80797101,  0.80797101]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grid_search(): # performing grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    param = {'penalty': ['l1', 'l2'],\n",
    "    'C':[0.01, 0.1, 1, 10, 100]\n",
    "            }\n",
    "\n",
    "    log = LogisticRegression().fit(X_train, y_train)\n",
    "    grid = GridSearchCV(log, param, cv = 3, scoring = 'recall')\n",
    "    grid.fit(X_train, y_train)\n",
    "    grid_mean_score = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "    parameters = [param.parameters for param in grid.grid_scores_]\n",
    "    l1_score = [grid_mean_score[even] for even in range(len(grid_mean_score)) if even%2 == 0]\n",
    "    l2_score = [grid_mean_score[odd] for odd in range(len(grid_mean_score)) if odd%2 != 0 ]\n",
    "    ans = np.array([l1_score, l2_score])\n",
    "    ans = ans.transpose()\n",
    "    \n",
    "    \n",
    "    return ans\n",
    "grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
